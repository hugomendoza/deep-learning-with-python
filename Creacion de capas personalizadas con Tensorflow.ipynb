{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de capas personalizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ciertas ocasiones es posible que se desee implementar una nueva capa de la red neuronal artificial para la que no existe una implementación en Tensorflow o Keras. En estos casos podemos utilizar Tensorflow para crear capas personalizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_housing = datasets.boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02177</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>7.610</td>\n",
       "      <td>15.7</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>395.38</td>\n",
       "      <td>3.11</td>\n",
       "      <td>42.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.89822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>4.970</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>375.52</td>\n",
       "      <td>3.26</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>6.037</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.9853</td>\n",
       "      <td>5.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.01</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.69311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.376</td>\n",
       "      <td>88.4</td>\n",
       "      <td>2.5671</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.43</td>\n",
       "      <td>14.65</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.28392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>5.708</td>\n",
       "      <td>74.3</td>\n",
       "      <td>4.7211</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>391.13</td>\n",
       "      <td>11.74</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.18702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>5.536</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.5804</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>23.60</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.09740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4118</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>26.42</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.15505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.628</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.5166</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>169.27</td>\n",
       "      <td>16.65</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.62864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>5.019</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4394</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>34.41</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "0  1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
       "1  0.02177  82.5   2.03   0.0  0.415  7.610   15.7  6.2700   2.0  348.0   \n",
       "2  4.89822   0.0  18.10   0.0  0.631  4.970  100.0  1.3325  24.0  666.0   \n",
       "3  0.03961   0.0   5.19   0.0  0.515  6.037   34.5  5.9853   5.0  224.0   \n",
       "4  3.69311   0.0  18.10   0.0  0.713  6.376   88.4  2.5671  24.0  666.0   \n",
       "5  0.28392   0.0   7.38   0.0  0.493  5.708   74.3  4.7211   5.0  287.0   \n",
       "6  9.18702   0.0  18.10   0.0  0.700  5.536  100.0  1.5804  24.0  666.0   \n",
       "7  4.09740   0.0  19.58   0.0  0.871  5.468  100.0  1.4118   5.0  403.0   \n",
       "8  2.15505   0.0  19.58   0.0  0.871  5.628  100.0  1.5166   5.0  403.0   \n",
       "9  1.62864   0.0  21.89   0.0  0.624  5.019  100.0  1.4394   4.0  437.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     21.0  396.90  18.72  15.2  \n",
       "1     14.7  395.38   3.11  42.3  \n",
       "2     20.2  375.52   3.26  50.0  \n",
       "3     20.2  396.90   8.01  21.1  \n",
       "4     20.2  391.43  14.65  17.7  \n",
       "5     19.6  391.13  11.74  18.5  \n",
       "6     20.2  396.90  23.60  11.3  \n",
       "7     14.7  396.90  26.42  15.6  \n",
       "8     14.7  169.27  16.65  15.6  \n",
       "9     21.2  396.90  34.41  14.4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "features = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n",
    "\n",
    "df_train = pd.DataFrame(np.column_stack([X_train, y_train]), columns=features)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalando el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_prep = scaler.fit_transform(X_train)\n",
    "X_val_prep = scaler.transform(X_val)\n",
    "X_test_prep = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion de la arquitectura de la Red Neuronal Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de capas sin parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las capas sin parámetros aplican transformaciones sobre los valores de entrada. Algunos ejemplos de capas de este tipo que se encuentran implementados en Keras son: _keras.layers.Flatten_ o _keras.layers.ReLU_. \n",
    "\n",
    "En estos casos, la mejor forma de crear este tipo de capas es desarrollar una función personalizada y utilizarla junto con la construcción _keras.layers.Lambda_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Capa personalizada que eleva al cuadrado los valores de entrada\n",
    "square_layer = keras.layers.Lambda(lambda x: tf.square(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta capa se utiliza de la misma forma que el resto de capas que se encuentran implementadas en Keras por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]))\n",
    "network.add(layers.Dense(10, activation='relu'))\n",
    "network.add(square_layer)\n",
    "network.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                420       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 741 (2.89 KB)\n",
      "Trainable params: 741 (2.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='adam',\n",
    "    metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 1s 27ms/step - loss: 623.7374 - mae: 23.2361 - val_loss: 587.2205 - val_mae: 22.4653\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 596.5098 - mae: 22.6389 - val_loss: 570.7358 - val_mae: 22.0856\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 578.6555 - mae: 22.2073 - val_loss: 554.4739 - val_mae: 21.7175\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 557.4581 - mae: 21.7056 - val_loss: 530.5547 - val_mae: 21.1575\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 526.0392 - mae: 20.8643 - val_loss: 492.3597 - val_mae: 20.1862\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 481.8240 - mae: 19.9137 - val_loss: 447.3049 - val_mae: 19.1664\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 429.4630 - mae: 18.8110 - val_loss: 398.9543 - val_mae: 17.8593\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 369.6231 - mae: 17.2224 - val_loss: 351.9343 - val_mae: 16.4758\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 317.4542 - mae: 15.7924 - val_loss: 319.7232 - val_mae: 16.0999\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 279.4664 - mae: 14.7142 - val_loss: 292.4628 - val_mae: 15.2877\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 249.0753 - mae: 13.7544 - val_loss: 253.4491 - val_mae: 14.0950\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 216.0469 - mae: 12.6601 - val_loss: 215.7374 - val_mae: 13.0280\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 184.3647 - mae: 11.5351 - val_loss: 181.4421 - val_mae: 11.9039\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 157.1652 - mae: 10.4684 - val_loss: 151.1962 - val_mae: 10.7767\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 134.8947 - mae: 9.5807 - val_loss: 128.7681 - val_mae: 9.8356\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 117.3771 - mae: 8.8636 - val_loss: 109.0366 - val_mae: 8.9183\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 103.5325 - mae: 8.2394 - val_loss: 95.6113 - val_mae: 8.1997\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 92.7686 - mae: 7.7723 - val_loss: 85.8866 - val_mae: 7.8562\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 83.9179 - mae: 7.3897 - val_loss: 77.6202 - val_mae: 7.5138\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 75.7873 - mae: 7.0121 - val_loss: 71.9954 - val_mae: 7.2096\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 69.0309 - mae: 6.6679 - val_loss: 66.7599 - val_mae: 6.9730\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.9856 - mae: 6.3609 - val_loss: 62.2288 - val_mae: 6.7383\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 57.4789 - mae: 6.0697 - val_loss: 59.1662 - val_mae: 6.5141\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.4435 - mae: 5.7757 - val_loss: 55.4852 - val_mae: 6.1995\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.6003 - mae: 5.5101 - val_loss: 51.5463 - val_mae: 5.8888\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.2204 - mae: 5.2555 - val_loss: 49.0829 - val_mae: 5.6600\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.4774 - mae: 5.0096 - val_loss: 46.4471 - val_mae: 5.3988\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.6584 - mae: 4.7355 - val_loss: 43.6947 - val_mae: 5.1467\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.5272 - mae: 4.5193 - val_loss: 41.9145 - val_mae: 4.9484\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29.7402 - mae: 4.2897 - val_loss: 40.1557 - val_mae: 4.7131\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 26.9750 - mae: 4.0842 - val_loss: 37.9810 - val_mae: 4.4848\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.8557 - mae: 3.9197 - val_loss: 36.4815 - val_mae: 4.3110\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.8950 - mae: 3.7345 - val_loss: 35.5078 - val_mae: 4.1807\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.3994 - mae: 3.6160 - val_loss: 34.0234 - val_mae: 4.0063\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6495 - mae: 3.4616 - val_loss: 33.2601 - val_mae: 3.8868\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.4875 - mae: 3.3459 - val_loss: 31.6273 - val_mae: 3.7603\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 17.2843 - mae: 3.2061 - val_loss: 29.9425 - val_mae: 3.6416\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 16.1393 - mae: 3.1190 - val_loss: 29.3403 - val_mae: 3.5472\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.2969 - mae: 3.0049 - val_loss: 28.6078 - val_mae: 3.4703\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 14.6279 - mae: 2.9423 - val_loss: 27.9127 - val_mae: 3.3895\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 13.7650 - mae: 2.8514 - val_loss: 26.5834 - val_mae: 3.2974\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 13.2284 - mae: 2.7782 - val_loss: 26.1359 - val_mae: 3.2547\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.6633 - mae: 2.7217 - val_loss: 25.9067 - val_mae: 3.2310\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 12.3285 - mae: 2.6777 - val_loss: 25.6235 - val_mae: 3.1883\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 11.8379 - mae: 2.6160 - val_loss: 25.3869 - val_mae: 3.1817\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.4154 - mae: 2.5624 - val_loss: 24.6072 - val_mae: 3.1405\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.2664 - mae: 2.5564 - val_loss: 24.0881 - val_mae: 3.1049\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.0568 - mae: 2.5231 - val_loss: 23.8240 - val_mae: 3.0957\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.7429 - mae: 2.4722 - val_loss: 23.2293 - val_mae: 3.0457\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 10.4491 - mae: 2.4427 - val_loss: 22.8133 - val_mae: 3.0088\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(X_train_prep, \n",
    "                      y_train, \n",
    "                      epochs=50, \n",
    "                      validation_data=(X_val_prep, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22.760721],\n",
       "       [20.390284],\n",
       "       [23.223104],\n",
       "       [19.164227],\n",
       "       [37.117233],\n",
       "       [20.965393],\n",
       "       [20.302502],\n",
       "       [16.84701 ],\n",
       "       [23.275455],\n",
       "       [25.78372 ],\n",
       "       [26.059137],\n",
       "       [21.670778],\n",
       "       [59.874493],\n",
       "       [24.749012],\n",
       "       [15.68661 ],\n",
       "       [27.712446],\n",
       "       [21.64017 ],\n",
       "       [25.134048],\n",
       "       [20.752739],\n",
       "       [11.424868],\n",
       "       [ 8.082136],\n",
       "       [15.226792],\n",
       "       [17.312689],\n",
       "       [49.354935],\n",
       "       [27.907757],\n",
       "       [32.77675 ],\n",
       "       [23.165483],\n",
       "       [11.31893 ],\n",
       "       [41.788773],\n",
       "       [ 7.276226],\n",
       "       [22.319553],\n",
       "       [16.659508],\n",
       "       [32.284847],\n",
       "       [18.30059 ],\n",
       "       [14.889567],\n",
       "       [21.172192],\n",
       "       [38.529568],\n",
       "       [14.002282],\n",
       "       [23.03311 ],\n",
       "       [14.44152 ],\n",
       "       [29.86906 ],\n",
       "       [20.672985],\n",
       "       [21.270094],\n",
       "       [23.04155 ],\n",
       "       [34.428493],\n",
       "       [33.239475],\n",
       "       [18.843918],\n",
       "       [34.66697 ],\n",
       "       [21.911268],\n",
       "       [39.510468],\n",
       "       [14.404311]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
